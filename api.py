from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import os
import json
import re
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
from groq import Groq
from openai import OpenAI

# =========================
# ุฅุนุฏุงุฏ ุงูุชุทุจูู
# =========================



app = FastAPI(title="YE - Pro Student Tutor v2")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


OPENROUTER_API_KEY = "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"
GROQ_API_KEY = "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"







openrouter_client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key= OPENROUTER_API_KEY
)




groq_client = Groq(
    api_key= GROQ_API_KEY
)










# =========================
# ูุชุบูุฑุงุช ูููุงุฑุฏ
# =========================
BASE_SUBJECTS_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "data", "subjects")
embed_model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")

# ุฌูุณุงุช ุงููุณุชุฎุฏููู (ูุชุฎุฒูู pending pages ุฃู pending exams)
sessions: Dict[str, Dict[str, Any]] = {}

# ุญุฏูุฏ ูุณูุงุณุงุช
MAX_PAGES_EXPLAIN_SUMMARY = 3      # ุฃูุตู ุตูุญุงุช ูุดุฑุญ/ุชูุฎูุต ุนูุฏ ุงูุฅุฏุฎุงู
MAX_PAGES_EXAMS = 5                # ุฃูุตู ุตูุญุงุช ูุจุญุซ ุงููุฒุงุฑู ุนุจุฑ ุงูุตูุญุงุช
EXAMS_BATCH_SIZE = 10              # ุฏูุนุฉ ุนุฑุถ ุฃุณุฆูุฉ ูุฒุงุฑู
UNIT_BATCH_PAGES = 3               # ุนุฏุฏ ุตูุญุงุช ูู ูู ุฏูุนุฉ ุนูุฏ ุดุฑุญ/ุชูุฎูุต ุงููุญุฏุฉ
QA_TOP_K = 3                       # ุนุฏุฏ ูุชุงุฆุฌ FAISS ููุณุคุงู

# =========================
# ููุฏูู ุงูุทูุจ
# =========================
class AskRequest(BaseModel):
    user_id: str
    subject: str             # ุงุณู ุงููุงุฏุฉ ููุง ูู ุงููุฌูุฏ (ูุซุงู: ุงุญูุงุก)
    logic_type: int = 1      # 1 = ุตุงุฑู ูู ุงููุชุงุจ
    mode: str                # "ุดุฑุญ" ุฃู "ุชูุฎูุต" ุฃู "ุณุคุงู" ุฃู "ูุฒุงุฑู"
    input_type: str          # "ุตูุญุฉ" ุฃู "ูุญุฏุฉ" ุฃู "ุจุฑููุช"
    content: str             # ูุต ุงููุณุชุฎุฏู ุฃู ุฃุฑูุงู ุงูุตูุญุงุช ุฃู "ููู"/"ููู" ุฃู "ุนูููู"
    summary_level: int = 3   # 1..5 (ููุชูุฎูุต)
    unit_name: Optional[str] = None # ุงูุญูู ุงูุฌุฏูุฏ ูุงุณุชูุงู ุงููุญุฏุฉ ูู ุงููุฑููุช ุฅูุฏ
    lesson_name: Optional[str] = None # ุงุณู ุงูุฏุฑุณ (ููุฑูุงุถูุงุช)
# =========================
# ุฏูุงู ูุณุงุนุฏุฉ ููุฑุงุกุฉ ุงููุชุจ ูุงูุฃุณุฆูุฉ
# =========================
def subject_book_path(subject: str) -> str:
    return os.path.join(BASE_SUBJECTS_DIR, subject, f"{subject}.json")

def subject_exams_dir(subject: str) -> str:
    return os.path.join(BASE_SUBJECTS_DIR, subject, "exams")

def load_json_safe(path: str):
    if not os.path.isfile(path):
        return None
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return None

def find_unit(book_data: List[dict], query: str):
    """ุงูุจุญุซ ุนู ุงููุญุฏุฉ ุจุงูุงุณู ุฃู ุจุงูุฑูู (ูุทุงุจูุฉ ุฌุฒุฆูุฉ)"""
    q = query.strip()
    for unit in book_data:
        if q == unit.get("ุงุณู_ุงููุญุฏุฉ") or q == str(unit.get("ุฑูู_ุงููุญุฏุฉ")):
            return unit
    # ูุญุงููุฉ ูุทุงุจูุฉ ุฌุฒุฆูุฉ
    for unit in book_data:
        if q in unit.get("ุงุณู_ุงููุญุฏุฉ", ""):
            return unit
    return None

def fetch_pages_by_numbers(book_data: List[dict], page_nums: List[int]):
    found = []
    missing = []
    for p in page_nums:
        found_flag = False
        for unit in book_data:
            for page in unit.get("ุงูุตูุญุงุช", []):
                if page.get("ุฑูู_ุงูุตูุญุฉ") == p:
                    found.append(page)
                    found_flag = True
                    break
            if found_flag:
                break
        if not found_flag:
            missing.append(p)
    return found, missing
def extract_relevant_book_texts(book_data, query, top_k=5):
    """
    ุชุจุญุซ ูู ุงููุชุงุจ ุฃููุงู (FAISS + ูููุงุช)
    ูุชุฑุฌุน ูุตูุต ุงูุตูุญุงุช ุงููุฑุชุจุทุฉ ูุนููุงู ุจุงูููุถูุน
    """
    texts, metas = extract_all_texts_and_metas(book_data)

    # ุจุญุซ ุฏูุงูู
    sem_results, _ = faiss_search(texts, query, top_k=top_k)

    # ุจุญุซ ูุจุงุดุฑ ุจุงููููุงุช
    keywords = re.findall(r'[\u0600-\u06FF]{3,}', query)
    direct_hits = []

    for txt in texts:
        if any(k in txt for k in keywords):
            direct_hits.append(txt)

    # ุฏูุฌ ุจุฏูู ุชูุฑุงุฑ
    final_texts = []
    for t in direct_hits + sem_results:
        if t not in final_texts:
            final_texts.append(t)

    return final_texts[:top_k]

def extract_all_texts_and_metas(book_data: List[dict]):
    texts = []
    metas = []
    for unit in book_data:
        for page in unit.get("ุงูุตูุญุงุช", []):
            texts.append(page.get("ูุต_ุงูุตูุญุฉ", ""))
            metas.append({
                "unit": unit.get("ุงุณู_ุงููุญุฏุฉ"),
                "page": page.get("ุฑูู_ุงูุตูุญุฉ")
            })
    return texts, metas

def faiss_search(texts: List[str], query: str, top_k: int = QA_TOP_K):
    if not texts:
        return [], []
    emb = embed_model.encode(texts, convert_to_numpy=True)
    faiss.normalize_L2(emb)
    index = faiss.IndexFlatIP(emb.shape[1])
    index.add(emb)
    q_emb = embed_model.encode([query], convert_to_numpy=True)
    faiss.normalize_L2(q_emb)
    D, I = index.search(q_emb, k=min(top_k, len(texts)))
    results = []
    idxs = []
    for i in I[0]:
        results.append(texts[i])
        idxs.append(i)
    return results, idxs

# =========================
# ุจุฑููุจุชุงุช ุฌุงูุฒุฉ
# =========================
def system_prompt_strict_explain(subject: str):
    return (
       f"ุฃูุช ุงูุขู ูู ูุถุน ูุฏุฑุณ ุฏุงุฎู ุงูุตู ููุงุฏุฉ {subject}. "
        "ุชุชุนุงูู ูุน ุงูุทุงูุจ ููุฃูู ุชุดุฑุญ ูู ุฃุซูุงุก ุงูุญุตุฉ ุงูุฏุฑุงุณูุฉ.\n\n"
        "ุงูููุงุนุฏ ุงูุฃุณุงุณูุฉ (ููู ุงูุงูุชุฒุงู ุจูุง ุจุฏูุฉ):\n"
        "1) ูุตุฏุฑ ุงูุฅุฌุงุจุฉ ุงููุญูุฏ ูู ุงููุชุงุจ ุงููุนุทู ูู ููุทุ ููุง ููุณูุญ ุจุงุณุชุฎุฏุงู ุฃู ูุนูููุงุช ูู ุฎุงุฑุฌ ุงููุชุงุจ.\n"
        "2) ูุง ุชุถู ูุนุฑูุฉ ุนุงูุฉุ ููุง ุฃูุซูุฉ ุฎุงุฑุฌูุฉุ ููุง ุงุฌุชูุงุฏ ุดุฎุตู.\n"
        "3) ุฌููุน ุงูุฅุฌุงุจุงุช ูุฌุจ ุฃู ุชููู ุฅูุง ููููุง ูุจุงุดุฑูุง ูู ูุต ุงููุชุงุจ ุฃู ุดุฑุญูุง ูุจุณุทูุง ููุนูู ููุฌูุฏ ุตุฑุงุญุฉ ูู ุงููุชุงุจ.\n\n"
        "ุฃุณููุจ ุงูุดุฑุญ:\n"
        "- ุงูุฃุณููุจ ุชุนููููุ ูุฑุชุจุ ููุฃูู ุฏุงุฎู ุงูุตู.\n"
        "- ูููู ุชูุณูู ุงูุดุฑุญ ุฅูู ููุงุท ุฃู ุฎุทูุงุช ุนูุฏ ุงูุญุงุฌุฉ.\n\n"
        "ูู ุญุงู ูู ุชุฌุฏ ุฅุฌุงุจุฉ ุฏุงุฎู ูุต ุงููุชุงุจ:\n"
        "ูู ุจูุถูุญ: (ูุง ุชูุฌุฏ ุฅุฌุงุจุฉ ูุจุงุดุฑุฉ ููุฐุง ุงูุทูุจ ูู ูุต ุงููุชุงุจ)ุ ููุง ุชุญุงูู ุงูุชุฎููู ุฃู ุงูุฅุถุงูุฉ."
    )

def system_prompt_strict_summary(subject: str, level: int):
    levels = {1: "ููุตู ุฌุฏุงู", 2: "ุดุงูู", 3: "ูุชูุณุท", 4: "ูุฎุชุตุฑ", 5: "ูุฎุชุตุฑ ุฌุฏุงู ูู ููุงุท"}
    return (
        f"ุฃูุช ููุฎูุต ูุงูุฑ ููุงุฏุฉ {subject}. ุงูุชุฒู ุจุงููุต ุงูููุฏู ููุท. ูุฎุต ุจูุณุชูู: {levels.get(level,'ูุชูุณุท')}. "
        "ูุง ุชุถู ูุนูููุงุช ุฎุงุฑุฌ ุงููุต. ุงูุชูุณูู ูููู ูุงุถุญูุง ูููุงุท ุนูุฏ ุงูุญุงุฌุฉ."
    )

def system_prompt_strict_qa(subject: str):
    return (
        f"ุฃูุช ูุฏุฑุณ ูุฌูุจ ูุจุงุดุฑุฉ ูู ูุต ูุชุงุจ ูุงุฏุฉ {subject}. ุฃุฌุจ ุจุฌููุฉ ุฃู ุฌููุชูู ููุชุจุณุชูู ุฃู ูุณุชุฎูุตุฉ ูู ุงููุต ููุท. "
        "ุฅู ูู ุชุฌุฏ ุงูุฅุฌุงุจุฉ ุฏุงุฎู ุงููุต ูู: 'ุนุฐุฑุงูุ ูุฐู ุงููุนูููุฉ ุบูุฑ ูุชููุฑุฉ ูู ุงููุชุงุจ'."
    )

def system_prompt_strict_exams(subject: str):
    return (
        f"ุฃูุช ูุณุงุนุฏ ููุฃูุชุญุงูุงุช ูุดูุงุฏุฉ ุงูุซุงูููุฉ ูู ูุงุฏุฉ {subject}. ุงุณุชุฎุฑุฌ ุงูุฃุณุฆูุฉ ุงููุทุงุจูุฉ ูู ูููุงุช ุงูุฃุณุฆูุฉ ููู ูุนุงููุฑ ุงููุณุชุฎุฏู. "
        "ูุง ุชุถู ุฃุณุฆูุฉ ุฃู ุชุบูุฑ ูู ูุตูุต ุงูุฃุณุฆูุฉุ ููุท ุงุนุฑุถ ุงููุตูุต ููุง ูู ูุน ุฐูุฑ ุงูุณูุฉ ูุงูุฌุฒุก ูููุน ุงูุณุคุงู."
    )

# =========================
# ุชุนูููุงุช ุงูุงุณุชุฎุฏุงู (ุนูููู)
# =========================
USAGE_HELP = {
    "ุตูุญุฉ": (
        "ุฃูุช ูู ูุถุน ุงูุตูุญุงุช. ุงูุชุจ ุฃุฑูุงู ุงูุตูุญุงุช ููุตููุฉ ุจููุงุตู.\n"
        f"ูุซุงู: 45 ุฃู 45,47\n"
        f"ููุงุญุธุฉ: ุงูุญุฏ ุงูุฃูุตู ููุตูุญุงุช ููุง ูู {MAX_PAGES_EXPLAIN_SUMMARY} ุตูุญุงุช ููุดุฑุญ/ุชูุฎูุต."
    ),
    "ูุญุฏุฉ": (
        "ุฃูุช ูู ูุถุน ุงููุญุฏุฉ. ุงูุชุจ ุงุณู ุงููุญุฏุฉ ุฃู ุฑูููุง ููุง ูู ููุชูุจ ูู ูุญุชูู ุงููุชุงุจ.\n"
        f"ุณูุชู ุดุฑุญ {UNIT_BATCH_PAGES} ุตูุญุฉ ูู ูู ูุฑุฉ. ุงูุชุจ 'ููู' ููุงุณุชูุฑุงุฑ ุฃู 'ููู' ูุฅููุงุก ุงูุฌูุณุฉ."
    ),
    "ุจุฑููุช": (
        "ุฃูุช ูู ูุถุน ุงูุจุฑููุช. ุงูุชุจ ููุถูุนูุง ุฃู ุณุคุงูุงู ูุตูุงู. ููููู ุชุญุฏูุฏ ูุญุฏุฉ ูุนููุฉ ูุชุณุฑูุน ุงูุจุญุซ ูุฏูุชู."
    ),
    "ุณุคุงู": (
        "ุฃูุช ูู ูุถุน ุงูุณุคุงู. ุงูุชุจ ุณุคุงูุงู ูุตูุงู ูููููุงู. ููุถู ุชุญุฏูุฏ ุงููุญุฏุฉ ุงููุฎุชุตุฉ ุจุงูุณุคุงู ููุชุงุฆุฌ ุฃุฏู."
    ),
    "ูุฒุงุฑู": (
        "ุฃูุช ูู ูุถุน ุงูุฃุณุฆูุฉ ุงููุฒุงุฑูุฉ.\n"
        "ุงูุตูุบ ุงูููุจููุฉ:\n"
        "- ุจุญุซ ุจุงููุญุฏุฉ: <ุณูุฉ>,<ุงุณู ุงููุญุฏุฉ>  ูุซุงู: 2018,ุงูุบุฏุฏ ุงูุตูุงุก\n"
        f"- ุจุญุซ ุจุงูุตูุญุงุช: <ุณูุฉ>,<ุตูุญุฉ1>,<ุตูุญุฉ2>  (ุงูุญุฏ ุงูุฃูุตู ููุตูุญุงุช ููุง {MAX_PAGES_EXAMS})\n"
        "- ุจุญุซ ุจุงูุจุฑููุช: <ุณูุฉ>,<ููุถูุน>  ูุซุงู: 2019,ุงูุชููุณ\n"
        "ููููู ูุชุงุจุฉ 'ุงููู' ุจุฏูุงู ูู ุงูุณูุฉ ููุจุญุซ ุนุจุฑ ูู ุงูุณููุงุช."
    )
}
def ai_extract_topics_from_pages(page_texts: List[str]):
    """
    ูููู ูุตูุต ุงูุตูุญุงุช ููุณุชุฎุฑุฌ ุงูููุงุถูุน ุงูุฃุณุงุณูุฉ ููุฏุฑุณ
    """
    context = "\n".join(page_texts)

    prompt = f"""
ุฃูุช ูุฏุฑุณ ุฎุจูุฑ ูู ุชุญููู ุงูููุงูุฌ.
ุงูุฑุฃ ูุต ุงูุฏุฑุณ ุงูุชุงูู ูุงุณุชุฎุฑุฌ:

1. ุงูููุงุถูุน ุงูุฑุฆูุณูุฉ
2. ุงูููุงููู ุงูุฃุณุงุณูุฉ
3. ูุง ุงูุฐู ูุฑูุฒ ุนููู ุงูุฏุฑุณ ูุนููุงู

ุฃุนุฏ ุงููุชูุฌุฉ ูููุงุท ูุฎุชุตุฑุฉ ููุงุถุญุฉ.

ูุต ุงูุฏุฑุณ:
{context}
"""

    try:
        response = groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            temperature=0.0,
            messages=[
                {"role": "system", "content": "ุฃูุช ูุญูู ููุงูุฌ ุฏููู ุฌุฏุงู."},
                {"role": "user", "content": prompt}
            ]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print("โ ุฎุทุฃ ุงุณุชุฎุฑุงุฌ ุงูููุงุถูุน:", e)
        return ""

# =========================
# ุฏูุงู ุงููุณุงุนุฏุฉ ููู ูุฒุงุฑู
# =========================
def parse_exams_input(content: str):
    parts = [p.strip() for p in content.split(",") if p.strip() != ""]
    if not parts:
        return None, None
    year = parts[0]
    rest = parts[1:]
    return year, rest

def restrict_book_to_unit(book_data: List[dict], unit_name: str):
    """
    ุชุญุตุฑ ุงููุชุงุจ ุฏุงุฎู ูุญุฏุฉ ูุงุญุฏุฉ ููุท
    """
    for unit in book_data:
        if unit_name == unit.get("ุงุณู_ุงููุญุฏุฉ") or unit_name == str(unit.get("ุฑูู_ุงููุญุฏุฉ")):
            return [unit]
        if unit_name in unit.get("ุงุณู_ุงููุญุฏุฉ", ""):
            return [unit]
    return None

def collect_exam_questions_by_years(subject: str, years: List[str]):
    exams_dir = subject_exams_dir(subject)
    found = []
    if not os.path.isdir(exams_dir):
        return found
    for f in os.listdir(exams_dir):
        if not f.lower().endswith(".json"):
            continue
        file_year = os.path.splitext(f)[0].strip()
        if "ุงููู" not in years and file_year not in [str(y) for y in years]:
            continue
        data = load_json_safe(os.path.join(exams_dir, f))
        if not data:
            continue
        for block in data:
            questions = block.get("ุงูุงุณุฆูุฉ", [])
            for q in questions:
                found.append({
                    "ุณูุฉ": block.get("ุณูุฉ_ุงูุงูุชุญุงู", file_year),
                    "ุงูุฌุฒุก": block.get("ุงูุฌุฒุก", ""),
                    "ุงูููุน": block.get("ููุน_ุงูุณุคุงู", ""),
                    "ุงููุต": q
                })
    return found



def help_for_mode(mode: str, input_type: str = None) -> str:
    if mode == "ุดุฑุญ":
        if input_type == "ุตูุญุฉ": return USAGE_HELP["ุตูุญุฉ"]
        if input_type == "ูุญุฏุฉ": return USAGE_HELP["ูุญุฏุฉ"]
        return USAGE_HELP["ุจุฑููุช"]
    if mode == "ุชูุฎูุต":
        return USAGE_HELP["ุจุฑููุช"] + "\nุงุฎุชุฑ ุฏุฑุฌุฉ ุงูุชูุฎูุต ูู 1 ุฅูู 5."
    if mode == "ุณุคุงู": return USAGE_HELP["ุณุคุงู"]
    if mode == "ูุฒุงุฑู": return USAGE_HELP["ูุฒุงุฑู"]
    return "ุงุณุชุฎุฏู ุงูุชุทุจูู ูุดุฑุญ ุฃู ุชูุฎูุต ุฃู ุณุคุงู ุฃู ุฃุณุฆูุฉ ูุฒุงุฑูุฉ."

def pages_with_headers(pages):
    blocks = []
    for p in pages:
        blocks.append(f"๐ ุงูุตูุญุฉ {p['ุฑูู_ุงูุตูุญุฉ']}:\n{p['ูุต_ุงูุตูุญุฉ']}")
    return "\n\n".join(blocks)

def enhanced_qa_search(book_data, query, top_k=5):
    texts, metas = extract_all_texts_and_metas(book_data)
    sem_results, idxs = faiss_search(texts, query, top_k=top_k)
    keywords = re.findall(r'[\u0600-\u06FF\w]{3,}', query)
    direct_hits = []
    direct_idxs = []
    for i, txt in enumerate(texts):
        if any(k in txt for k in keywords):
            direct_hits.append(txt)
            direct_idxs.append(i)
    final_texts = []
    final_idxs = []
    for t, i in zip(direct_hits, direct_idxs):
        if i not in final_idxs:
            final_texts.append(t)
            final_idxs.append(i)
    for t, i in zip(sem_results, idxs):
        if i not in final_idxs:
            final_texts.append(t)
            final_idxs.append(i)
    return final_texts[:top_k], final_idxs[:top_k]

def filter_exams_by_keyword(questions: list, keyword: str):
    """
    ุชุฑุฌุน ูู ุงูุฃุณุฆูุฉ ุงููุฒุงุฑูุฉ ุงูุชู ุชุญุชูู ุนูู ุงููููุฉ ุฃู ุงูุนุจุงุฑุฉ ุงููุทููุจุฉ
    """
    keyword = keyword.strip()
    if not keyword:
        return []

    matched = []
    for q in questions:
        text = q.get("ุงููุต", "")
        if keyword in text:
            matched.append(q)

    return matched


def extract_keywords(text: str):
    text = normalize_arabic(text)
    words = re.findall(r'[\u0600-\u06FF]{3,}', text)
    return set(words)



def filter_and_rank_exams(questions: list, user_text: str):
    """
    - ุฃู ุณุคุงู ูุญุชูู ุนูู ูููุฉ ูุงุญุฏุฉ ุนูู ุงูุฃูู ูุทูุน
    - ูุชู ุชุฑุชูุจ ุงูุฃุณุฆูุฉ ุญุณุจ ุนุฏุฏ ุงููููุงุช ุงููุชุทุงุจูุฉ (ุงูุฃูุซุฑ ุฃููุงู)
    """
    user_keywords = extract_keywords(user_text)
    if not user_keywords:
        return []

    scored_questions = []

    for q in questions:
        q_text = normalize_arabic(q.get("ุงููุต", ""))
        score = 0

        for kw in user_keywords:
            if kw in q_text:
                score += 1

        if score > 0:
            scored_questions.append((score, q))

    # ุชุฑุชูุจ: ุงูุฃุนูู ุชุทุงุจูุงู ุฃููุงู
    scored_questions.sort(key=lambda x: x[0], reverse=True)

    return [q for score, q in scored_questions]

def normalize_arabic(text: str) -> str:
    if not text:
        return ""

    text = text.lower()

    # ุฅุฒุงูุฉ ุงูุชุดููู
    text = re.sub(r'[ููููููููู]', '', text)

    # ุชูุญูุฏ ุงูุญุฑูู
    replacements = {
        "ุฃ": "ุง",
        "ุฅ": "ุง",
        "ุข": "ุง",
        "ู": "ู",
        "ุฉ": "ู",
        "ุค": "ู",
        "ุฆ": "ู",
    }

    for k, v in replacements.items():
        text = text.replace(k, v)

    # ุฅุฒุงูุฉ ุฃู ุงูุชุนุฑูู
    text = re.sub(r'\bุงู', '', text)

    # ุฅุฒุงูุฉ ุฃู ุดูุก ุบูุฑ ุญุฑูู ุนุฑุจูุฉ
    text = re.sub(r'[^\u0600-\u06FF\s]', ' ', text)

    # ุฅุฒุงูุฉ ุงููุณุงูุงุช ุงูุฒุงุฆุฏุฉ
    text = re.sub(r'\s+', ' ', text).strip()

    return text
def extract_keywords(query: str):
    normalized = normalize_arabic(query)
    words = normalized.split()

    # ุชุฌุงูู ุงููููุงุช ุงููุตูุฑุฉ ุฌุฏุงู
    return [w for w in words if len(w) >= 3]
def filter_exams_smart(questions: list, query: str, min_hits: int = 2):
    """
    ุชุฑุฌุน ุงูุฃุณุฆูุฉ ุงูุชู ุชุทุงุจู ุงูููุถูุน ุจุนุฏุฏ ูุงูู ูู ุงููููุงุช
    """
    keywords = extract_keywords(query)
    if not keywords:
        return []

    matched = []

    for q in questions:
        q_text = normalize_arabic(q.get("ุงููุต", ""))
        hits = 0

        for w in keywords:
            if w in q_text:
                hits += 1

        if hits >= min_hits:
            matched.append(q)

    return matched


# =========================
# ุฏูุงู ุงููุณุงุนุฏุฉ ููู ุฑูุงุถูุงุช
# =========================

def system_prompt_math_explain():
    return (
        "ุฃูุช ูุฏุฑุณ ุฑูุงุถูุงุช ุชุดุฑุญ ูู ููุฎุต ุงูุทุงูุจ ููุท.\n"
        "ุงูููุงุนุฏ:\n"
        "1) ุงูุดุฑุญ ูููู ุจููุณ ุฃุณููุจ ุงูููุฎุต.\n"
        "2) ูุง ุชุถู ููุงููู ุบูุฑ ููุฌูุฏุฉ.\n"
        "3) ุงูุดุฑุญ ูููู ุชุฏุฑูุฌู ูุจุณูุท.\n"
        "4) ุนูุฏ ุงูุฃูุซูุฉ: ุงุดุฑุญ ุฎุทูุฉ ุฎุทูุฉ ููุง ูู.\n"
         "5) ุฃุดุฑุญ ุจุงููุบุฉ ุงูุนุฑุจูุฉ ููุท.ุฐู"
    )


def load_math_lesson(branch: str, lesson_name: str):
    """
    branch: ุชูุงุถู / ุชูุงูู / ููุฏุณุฉ / ุฌุจุฑ
    lesson_name: ุงุณู ุงูุฏุฑุณ
    """
    base = os.path.join(BASE_SUBJECTS_DIR, "ุฑูุงุถูุงุช", branch)
    if not os.path.isdir(base):
        return None

    for f in os.listdir(base):
        if not f.endswith(".json"):
            continue
        name = os.path.splitext(f)[0]
        if lesson_name in name:
            return load_json_safe(os.path.join(base, f))

    return None



def system_prompt_math_explain():
    return (
        "ุฃูุช ูุฏุฑุณ ุฑูุงุถูุงุช ูุญุชุฑู.\n"
        "ุงุดุฑุญ ุงูุฏุฑุณ ููุทุงูุจ ุดุฑุญูุง ุชุนูููููุง ูุงุถุญูุง ุจุฃุณููุจ ูุจุณุท.\n"
        "ุงูุชุฒู ุจุงููุนูููุงุช ูุงูููุงููู ุงูููุฌูุฏุฉ ูู ุงููุต ููุท.\n"
        "ูุง ุชูุณุฎ ุงููุต ุญุฑูููุงุ ุจู ุงุดุฑุญ ุงููุนูู.\n"
        "ุงุณุชุฎุฏู ุฃูุซูุฉ ูู ุงููุต ุฅู ูุฌุฏุช.\n"
        "ุงูุดุฑุญ ูููู ูุชุณูุณู ููุฃูู ุชุดุฑุญ ูุทุงูุจ ุฏุงุฎู ุงูุตู.\n"
        "ุงูุชุฒู ุจุงูุดุฑุญ ุจุงููุบุฉ ุงูุนุฑุจูุฉ , ุงูููุงููู ูุงูุชุนุฑููุงุช ููู ุดู ุจุงููุบุฉ ุงูุนุฑุจูุฉ \n"
    )


def explain_math_lesson(lesson: dict):
    content = json.dumps(lesson, ensure_ascii=False, indent=2)

    prompt = f"""
ูุฐุง ููุฎุต ุฏุฑุณ ุฑูุงุถูุงุช:

{content}

ุงููุทููุจ:
ุงุดุฑุญ ูุฐุง ุงูุฏุฑุณ ุดุฑุญูุง ุชุนูููููุง ูุงุถุญูุง ููุทุงูุจ.
ูุงุชูุชุจ ุงู ูููุฉ ุงูุฌููุฒูุฉ ุงู ูููุฉ ุบูุฑ ุนุฑุจูุฉ ุงุซูุงุก ุงูุดุฑุญ
ุงูุดุฑุญ ุจุงููุบุฉ: ุงูุนุฑุจูุฉ ุงููุตุญู ููุท (ูููุน ุงูุตูููุฉ ูุงูุฅูุฌููุฒูุฉ)
2. ุงูุฑููุฒ: ุงุณุชุฎุฏู (ุฌุงุ ุฌุชุงุ ุธุง) ู (ุณุ ุต) ูุงูุฑููุฒ ุงูุนุฑุจูุฉ ุญุตุฑุงู.\n
- ุงูุชุจ ุงูุดุฑุญ ุจุงููุบุฉ ุงูุนุฑุจูุฉ ููุท
- ุงูุชุจ ุงูุดุฑุญ ุจุงููุบุฉ ุงูุนุฑุจูุฉ.
- ูุง ุชุณุชุฎุฏู LaTeX
- ูุง ุชุณุชุฎุฏู \text ุฃู \frac
- ุงูุชุจ ุงููุนุงุฏูุงุช ููุต ุนุงุฏู
ูุซุงู: ุต = 2ุณยฒ + 1

"""

    response = groq_client.chat.completions.create(
        model="llama-3.1-8b-instant",
        temperature=0.2,
        messages=[
            {"role": "system", "content": system_prompt_math_explain()},
            {"role": "user", "content": prompt}
        ]
    )

    return response.choices[0].message.content
import re


def solve_math_question_from_lesson(lesson: dict, user_text: str):
    lesson_text = json.dumps(lesson, ensure_ascii=False, indent=2)
    
    # ุงูุชุนูููุงุช ุงูุตุงุฑูุฉ ููุบุฉ ุงูุนุฑุจูุฉ ูุงูุฑููุฒ
    system_prompt = (
        "ุฃูุช ูุฏุฑุณ ุฑูุงุถูุงุช ูุญุชุฑู ูู ุชุทุจูู 'ูุณุงุฑ'. ุงูุชุฒู ุจุงูููุงุนุฏ ุงูุชุงููุฉ:\n"
        "1. ุงููุบุฉ: ุงูุนุฑุจูุฉ ุงููุตุญู ููุท (ูููุน ุงูุตูููุฉ ูุงูุฅูุฌููุฒูุฉ).\n"
        "- ุนูุฏ ุงุณุชูุงู ุณุคุงูุ ุงุจุญุซ ุฃููุงู ูู ุงูุฃูุซูุฉ ุงูููุฌูุฏุฉ ูู ุจูุงูุงุช ุงูุฏุฑุณ.""""
   - ุฅุฐุง ูุงู ุงูุณุคุงู ูุทุงุจูุงู ููุซุงู ููุฌูุฏุ ุงุฐูุฑ ุงูุญู ุงููููุฐุฌู ูู.
   - ุฅุฐุง ูุงู ุงูุณุคุงู ูุดุงุจูุงู ููุซุงู (ุจุงุฎุชูุงู ุงูุฃุฑูุงู ุฃู ุงูุฑููุฒ)ุ ุญู ุงููุณุฃูุฉ ุจููุณ ุงูุฎุทูุงุช ูุงูููุทู ุงููุชุจุน ูู ุฐูู ุงููุซุงู ุชูุงูุงู.
"""        "2. ุงูุฑููุฒ: ุงุณุชุฎุฏู (ุฌุงุ ุฌุชุงุ ุธุง) ู (ุณุ ุต) ุญุตุฑุงู.\n"
"""       - ุงูุชุจ ุงูุดุฑุญ ุจุงููุบุฉ ุงูุนุฑุจูุฉ ููุท
- ุงูุชุจ ุงูุดุฑุญ ุจุงููุบุฉ ุงูุนุฑุจูุฉ.
- ูุง ุชุณุชุฎุฏู LaTeX
- ูุง ุชุณุชุฎุฏู \text ุฃู \frac
- ุงูุชุจ ุงููุนุงุฏูุงุช ููุต ุนุงุฏู
ูุซุงู: ุต = 2ุณยฒ + 1
"""
  "3. ูุถุญ ุงูููุงููู ุงููุณุชุฎุฏูุฉ ูู ุงูุญู.\nููุงูุฉ ุงูุชุนูููุงุช."
  
    )

    try:
        # ุงูุงุชุตุงู ุจู Groq ุจุงุณุชุฎุฏุงู ููุฏูู DeepSeek R1 ุงูููุทุฑ
        response = openrouter_client.chat.completions.create(
            model="tngtech/deepseek-r1t-chimera:free", # ุงูููุฏูู ุงูุฃูุถู ุญุงููุงู
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ุจูุงูุงุช ุงูุฏุฑุณ:\n{lesson_text}\n\nุณุคุงู ุงูุทุงูุจ: {user_text}"}
            ],
            temperature=0.2
        )

        full_answer = response.choices[0].message.content

        # ุชูุธูู "ุฎุทูุงุช ุงูุชูููุฑ" (Thinking)
        clean_answer = re.sub(r'<think>.*?</think>', '', full_answer, flags=re.DOTALL).strip()
        
        # ุชุญููู ูุฏูู ูุฃู ุฑููุฒ ุฅูุฌููุฒูุฉ ูุฏ ุชููุช ูู ุงูููุฏูู
        clean_answer = clean_answer.replace("sin", "ุฌุง").replace("cos", "ุฌุชุง").replace("tan", "ุธุง")
        clean_answer = clean_answer.replace("x", "ุณ").replace("y", "ุต")
        
        return clean_answer
    except Exception as e:
        return f"ุนุฐุฑุงูุ ุญุฏุซ ุฎุทุฃ ูู ูุญุฑู ุงูุณุคุงู: {str(e)}"

def handle_math_request(req: AskRequest):
    user_id = req.user_id
    mode = req.mode.strip()          # ุดุฑุญ / ุณุคุงู
    branch = req.unit_name           # ุชูุงุถู / ุชูุงูู / ...
    user_text = req.content.strip()
    
    # ูุนุชูุฏ ุนูู ุงุณู ุงูุฏุฑุณ ุงููุฑุณู ูู ุงูุญูู ุงููุฎุตุต ูู
    lesson_name = req.lesson_name

    # ======================
    # ุนูููู
    # ======================
    if user_text == "ุนูููู":
        return {
            "answer": (
                "๐ ุฃูุช ูู ูุณู ุงูุฑูุงุถูุงุช:\n\n"
                "๐ข ุดุฑุญ ุงูุฏุฑุณ:\n"
                "- ุงุฎุชุฑ ุงููุฑุน\n"
                "- ุงุฎุชุฑ ุงูุฏุฑุณ\n"
                "- ุงุถุบุท (ุดุฑุญ ุงูุฏุฑุณ)\n"
                "- ุจุนุฏ ุงูุดุฑุญ ููููู ุงูุณุคุงู ุนู ุฃู ููุทุฉ ูู ุงูุดุฑุญ\n\n"
                "๐ต ุณุคุงู:\n"
                "- ุงุฎุชุฑ ุงูุฏุฑุณ\n"
                "- ุงูุชุจ ุงููุณุฃูุฉ\n"
                "- ุณูุญููุง ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุจููุณ ุฃุณููุจ ุงูููุฎุต\n"
            ),
            "session_active": False
        }

    # ======================
    # ุชุญูู ูู ุงููุฑุน
    # ======================
    if not branch:
        return {"answer": "โ๏ธ ุงุฎุชุฑ ูุฑุน ุงูุฑูุงุถูุงุช ุฃููุงู."}

    # ======================
    # ๐ข ูุณู ุดุฑุญ ุงูุฏุฑุณ
    # ======================
    if mode == "ุดุฑุญ":
        
        if not lesson_name:
             return {"answer": "โ๏ธ ูุฌุจ ุงุฎุชูุงุฑ ุงูุฏุฑุณ ุฃููุงู."}

        sess = sessions.get(user_id)

        # ูุญุฏุฏ ูู ูุฐุง ุทูุจ ุดุฑุญ ุฌุฏูุฏ (ุถุบุท ุงูุฒุฑ) ุฃู ุณุคุงู ูุชุงุจุนุฉุ
        is_start_new_explanation = (user_text == lesson_name)

        # ๐ข 1) ุจุฏุงูุฉ ุดุฑุญ ุฏุฑุณ ุฌุฏูุฏ
        if is_start_new_explanation or not sess or sess.get("lesson_name") != lesson_name:
            
            if not is_start_new_explanation and (not sess or sess.get("lesson_name") != lesson_name):
                 return {"answer": "โ๏ธ ุงูุฑุฌุงุก ุถุบุท ุฒุฑ (ุดุฑุญ ุงูุฏุฑุณ) ูุชุฃุณูุณ ุงูุดุฑุญ ุฃููุงู."}

            sessions.pop(user_id, None)

            lesson = load_math_lesson(branch, lesson_name)
            if not lesson:
                return {"answer": f"โ ูู ุฃุฌุฏ ุฏุฑุณ '{lesson_name}' ูู {branch}."}

            explanation = explain_math_lesson(lesson)

            sessions[user_id] = {
                "subject": "ุฑูุงุถูุงุช",
                "mode": "math_explain",
                "lesson": lesson,
                "lesson_name": lesson_name,
                "last_explanation": explanation
            }

            return {
                "answer": explanation,
                "session_active": False  # โ ุชุนุฏูู: ุฅุฎูุงุก ุฃุฒุฑุงุฑ ููู/ููู ูู ุงูุฑูุงุถูุงุช
            }

        # ๐ข 2) ุณุคุงู ุฏุงุฎู ููุณ ุงูุดุฑุญ (ูุชุงุจุนุฉ)
        if sess and sess.get("mode") == "math_explain":
            lesson = sess["lesson"]
            last_explanation = sess["last_explanation"]

            prompt = f"""
ุงูุดุฑุญ ุงูุณุงุจู:
{last_explanation}

ุณุคุงู ุงูุทุงูุจ:
{user_text}

ุงููุทููุจ:
- ุฃุฌุจ ุนูู ุงูุณุคุงู ุจุงูุงุนุชูุงุฏ ุนูู ููุณ ุงูุฏุฑุณ ููุท.
ูุงุชูุชุจ ุงู ูููุฉ ุงูุฌููุฒูุฉ ุงู ูููุฉ ุบูุฑ ุนุฑุจูุฉ ุงุซูุงุก ุงูุดุฑุญ
- ูุถูุญ ุงูููุฑุฉ ุจุฃุณููุจ ุชุนูููู ูุฑุชุจุท ุจุงูุดุฑุญ ุงูุณุงุจู.
- ุงูุชุจ ุงูุดุฑุญ ุจุงููุบุฉ ุงูุนุฑุจูุฉ ููุท
- ูุง ุชุณุชุฎุฏู LaTeX
- ูุง ุชุณุชุฎุฏู \text ุฃู \frac
- ุงูุชุจ ุงููุนุงุฏูุงุช ููุต ุนุงุฏู
ูุซุงู: ุต = 2ุณยฒ + 1
"""

            response = openrouter_client.chat.completions.create(
                model="tngtech/deepseek-r1t-chimera:free",
                temperature=0.2,
                messages=[
                    {"role": "system", "content": system_prompt_math_explain()},
                    {"role": "user", "content": prompt}
                ]
            )

            answer = response.choices[0].message.content

            return {
                "answer": answer,
                "session_active": False  # โ ุชุนุฏูู: ุฅุฎูุงุก ุฃุฒุฑุงุฑ ููู/ููู ูุน ุงุณุชูุฑุงุฑ ุงูุดุงุช
            }

        return {
            "answer": "โ๏ธ ุงุถุบุท (ุดุฑุญ ุงูุฏุฑุณ) ุฃููุงู.",
            "session_active": False
        }

    # ======================
    # ๐ต ูุณู ุงูุณุคุงู (ูููุตู ุชูุงูุงู)
    # ======================
    # ุงุจุญุซ ุนู ูุฐุง ุงูุฌุฒุก ุฏุงุฎู handle_math_request
    if mode == "ุณุคุงู":
        # ุงุณุชุฎุฏุงู ููู ุงูุชุฑุงุถู ูู ุญุงู ูู ูุฑุณู ุงูุชุทุจูู ุงุณูุงู ููุฏุฑุณ
        current_lesson = req.lesson_name or "ูุดุชูุฉ ุงูุฏูุงู ุงููุซูุซูุฉ ุงูุฏุงุฆุฑูุฉ"
        
        lesson = load_math_lesson(branch, current_lesson)
        if not lesson:
            return {"answer": f"โ๏ธ ูู ุฃุฌุฏ ููู ุงูุฏุฑุณ: {current_lesson}"}

        answer = solve_math_question_from_lesson(lesson, user_text)
        return {"answer": answer, "session_active": False}

# =========================
# ููุทุฉ ุงูููุงูุฉ /ask
# =========================
@app.get("/math/lessons")
def get_math_lessons(branch: str):
    math_root = os.path.join(BASE_SUBJECTS_DIR, "ุฑูุงุถูุงุช")
    branch_path = os.path.join(math_root, branch)

    if not os.path.isdir(branch_path):
        print("โ branch folder not found")
        return []

    lessons = []

    for fname in os.listdir(branch_path):
        if not fname.endswith(".json"):
            continue

        full_path = os.path.join(branch_path, fname)
        data = load_json_safe(full_path)

        if not data:
            continue

        lesson_name = data.get("ุงุณู_ุงูุฏุฑุณ")
        if lesson_name:
            lessons.append(lesson_name)

    print("โ lessons:", lessons)
    return lessons



@app.post("/ask")
async def ask(req: AskRequest):
    user_id = req.user_id
    # ๐ ุชุบููุฑ ุงููุงุฏุฉ = ุดุงุช ุฌุฏูุฏ
    prev = sessions.get(req.user_id)
    if prev and prev.get("subject") != req.subject:
      sessions.pop(req.user_id, None)

    subject = req.subject.strip()
    mode = req.mode.strip()
    input_type = req.input_type.strip()
    content = req.content.strip()
    # ===============================
# ๐ ูุณุงุฑ ุฎุงุต ููุงุฏุฉ ุงูุฑูุงุถูุงุช
# ===============================
    if subject == "ุฑูุงุถูุงุช":
        return handle_math_request(req)


    book_path = subject_book_path(subject)
    book_data = load_json_safe(book_path)
    if not book_data:
        return {"answer": f"ุงููุงุฏุฉ '{subject}' ุบูุฑ ูุชููุฑุฉ."}

    control_lower = content.strip().lower()
    if control_lower in ["ููู", "ุฎูุงุต", "ุดูุฑุง", "ุฅูุบุงุก"]:
        sessions.pop(user_id, None)
        return {"answer": "ุชู ุฅููุงู ุงูุฌูุณุฉ ุงูุญุงููุฉ.", "session_active": False}

    if content.strip() == "ุนูููู":
        return {"answer": help_for_mode(mode, input_type)}
    
    # ููุทู ุงูููุชุฑุฉ ุญุณุจ ุงููุญุฏุฉ (ูุฃุทูุงุฑ ุงูุดุฑุญ ูุงูุชูุฎูุต ูุงูุณุคุงู ุจููุน ุจุฑููุช)
    target_data = book_data
    if input_type == "ุจุฑููุช" or mode == "ุณุคุงู":
        if req.unit_name and req.unit_name not in ["ุงููู", ""]:
            unit = find_unit(book_data, req.unit_name)
            if unit:
                target_data = [unit] # ููุง ูุชู ุญุตุฑ ุงูุจุญุซ ุฏุงุฎู ุตูุญุงุช ุงููุญุฏุฉ ุงููุฎุชุงุฑุฉ ููุท
            else:
                return {"answer": f"ุนุฐุฑุงูุ ูู ุฃุฌุฏ ุงููุญุฏุฉ '{req.unit_name}' ูู ุงููุชุงุจ."}

    # "ููู" ูููุชุงุจุนุฉ
    

    # 1) ูุถุน "ุดุฑุญ"
    if mode == "ุดุฑุญ":
        if input_type == "ุตูุญุฉ":
            numbers = re.findall(r'\d+', content)
            if not numbers: return {"answer": "ุตูุบุฉ ุบูุฑ ุตุญูุญุฉ."}
            page_nums = [int(n) for n in numbers]
            if len(page_nums) > MAX_PAGES_EXPLAIN_SUMMARY: return {"answer": f"ุงูุญุฏ {MAX_PAGES_EXPLAIN_SUMMARY}."}
            found_pages, missing = fetch_pages_by_numbers(book_data, page_nums)
            if not found_pages: return {"answer": "ุงูุตูุญุงุช ุบูุฑ ููุฌูุฏุฉ."}
            context_text = pages_with_headers(found_pages)
            system_prompt = system_prompt_strict_explain(subject)
            try:
                response = openrouter_client.chat.completions.create(model="nvidia/nemotron-3-nano-30b-a3b:free", messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": f"ูุต ุงููุชุงุจ:\n{context_text}\n\nุทูุจ ุงูุทุงูุจ: ุงุดุฑุญ ุงููุญุชูู ุฃุนูุงู."}], temperature=0.1)
                answer = response.choices[0].message.content
            except Exception: answer = "ุฎุทุฃ ูู ุงูุชูููุฏ."
            if missing: answer += f"\n\nููุงุญุธุฉ: ูู ูุฌุฏ {missing}."
            return {"answer": answer, "references": [f"ุต {p.get('ุฑูู_ุงูุตูุญุฉ')}" for p in found_pages], "session_active": False}

        

        if input_type == "ุจุฑููุช":
            results, idxs = enhanced_qa_search(target_data, content, top_k=5)
            if not results: return {"answer": "ูู ุฃุฌุฏ ููุงุทุน ุตูุฉ."}
            context_text = "\n".join(results)
            system_prompt = system_prompt_strict_explain(subject)
            try:
                response = openrouter_client.chat.completions.create(
                    model="nvidia/nemotron-3-nano-30b-a3b:free", 
                    messages=[
                        {"role": "system", "content": system_prompt}, 
                        {"role": "user", "content": f"ูุต ุงููุชุงุจ:\n{context_text}\n\nุทูุจ ุงูุทุงูุจ: ุงุดุฑุญ ุงูููุถูุน '{content}' ุจูุงุกู ุนูู ุงููุต ุฃุนูุงู."}
                    ], 
                    temperature=0.1
                )
                answer = response.choices[0].message.content
            except Exception: answer = "ุฎุทุฃ ูู ุงูุชูููุฏ."
            _, metas = extract_all_texts_and_metas(target_data)
            refs = [f"{metas[i]['unit']} - ุต {metas[i]['page']}" for i in idxs]
            return {"answer": answer, "references": refs, "session_active": False}

    # 2) ูุถุน "ุชูุฎูุต"
    if mode == "ุชูุฎูุต":
        if input_type == "ุตูุญุฉ":
            numbers = re.findall(r'\d+', content)
            page_nums = [int(n) for n in numbers]
            found_pages, missing = fetch_pages_by_numbers(book_data, page_nums)
            context_text = pages_with_headers(found_pages)
            system_prompt = system_prompt_strict_summary(subject, req.summary_level)
            try:
                response = openrouter_client.chat.completions.create(model="nvidia/nemotron-3-nano-30b-a3b:free", messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": f"ูุต ุงููุชุงุจ:\n{context_text}\n\nุงููุทููุจ: ูุฎุต ุงููุญุชูู."}], temperature=0.15)
                answer = response.choices[0].message.content
            except Exception: answer = "ุฎุทุฃ ูู ุงูุชูุฎูุต."
            return {"answer": answer, "references": [f"ุต {p.get('ุฑูู_ุงูุตูุญุฉ')}" for p in found_pages], "session_active": False}

        if input_type == "ุจุฑููุช":
            texts, metas = extract_all_texts_and_metas(target_data)
            results, idxs = faiss_search(texts, content, top_k=QA_TOP_K)
            if not results: return {"answer": "ูุง ุชูุฌุฏ ููุงุทุน."}
            context_text = "\n".join(results)
            system_prompt = system_prompt_strict_summary(subject, req.summary_level)
            try:
                response = openrouter_client.chat.completions.create(
                    model="nvidia/nemotron-3-nano-30b-a3b:free", 
                    messages=[
                        {"role": "system", "content": system_prompt}, 
                        {"role": "user", "content": f"ูุต ุงููุชุงุจ:\n{context_text}\n\nุงููุทููุจ: ูุฎุต ุงูููุถูุน '{content}'."}
                    ], 
                    temperature=0.15
                )
                answer = response.choices[0].message.content
            except Exception: answer = "ุฎุทุฃ."
            refs = [f"{metas[i]['unit']} - ุต {metas[i]['page']}" for i in idxs]
            return {"answer": answer, "references": refs, "session_active": False}
    
    # 3) ูุถุน "ุณุคุงู"
    # 3) ูุถุน "ุณุคุงู" (ุชู ุชุญุณููู ููุตุจุญ ุฐููุงู ูุซู ุงูุดุฑุญ ููู ุจุฅุฌุงุจุฉ ูุฎุชุตุฑุฉ)
    if mode == "ุณุคุงู":
        # ูุณุชุฎุฏู enhanced_qa_search ุจุฏูุงู ูู faiss_search
        # ูุฐุง ูุฏูุฌ ุงูุจุญุซ ุจุงููููุงุช + ุงูุจุญุซ ุจุงููุนูู (ููุณ ููุฉ ุงูุดุฑุญ)
        results, idxs = enhanced_qa_search(target_data, content, top_k=5)
        
        if not results: 
            return {"answer": "ุนุฐุฑุงูุ ูู ุฃุฌุฏ ุฅุฌุงุจุฉ ุฏูููุฉ ูู ุงููุชุงุจ."}
            
        context_text = "\n".join(results)
        
        # ุจุฑููุช ูุฎุตุต: ุฐูู ูู ุงููููุ ููู ูุฎุชุตุฑ ูู ุงูุฑุฏ
        system_prompt = (
            f"ุฃูุช ูุฏุฑุณ ููุงุฏุฉ {subject}. ูุฏูู ูุตูุต ูู ุงููุชุงุจ ุงููุฏุฑุณู ุจุงูุฃุณูู.\n"
            "ุงููุทููุจ: ุฃุฌุจ ุนูู ุณุคุงู ุงูุทุงูุจ ุฅุฌุงุจุฉ ุฏูููุฉ ููุจุงุดุฑุฉ ุจูุงุกู ุนูู ุงููุตูุต.\n"
            "ุงูุดุฑุท: ุงูุฅุฌุงุจุฉ ูุฌุจ ุฃู ุชููู ูุฎุชุตุฑุฉ (ุณุทุฑูู ุฅูู ุซูุงุซุฉ ูุญุฏ ุฃูุตู). ุฃุนุท ุงูุฒุจุฏุฉ ููุท."
        )
        
        try:
            response = openrouter_client.chat.completions.create(
                model="nvidia/nemotron-3-nano-30b-a3b:free", 
                messages=[
                    {"role": "system", "content": system_prompt}, 
                    {"role": "user", "content": f"ูุต ุงููุชุงุจ:\n{context_text}\n\nุงูุณุคุงู: {content}"}
                ], 
                temperature=0.1
            )
            answer = response.choices[0].message.content
        except Exception: 
            answer = "ุญุฏุซ ุฎุทุฃ ุฃุซูุงุก ุตูุงุบุฉ ุงูุฅุฌุงุจุฉ."
            
        # ุงุณุชุฎุฑุงุฌ ุงููุฑุงุฌุน
        _, metas = extract_all_texts_and_metas(target_data)
        # ูุญุชุงุฌ ุงูุชุฃูุฏ ูู ุฃู idxs ุตุงูุญุฉ (ูุฃู enhanced ูุฏ ูุฑุฌุน ุงูุฏูุณุงุช ููุฑุฑุฉ ุงู ูุฑุชุจุฉ)
        refs = []
        for i in idxs:
            if i < len(metas):
                ref_str = f"{metas[i]['unit']} - ุต {metas[i]['page']}"
                if ref_str not in refs:
                    refs.append(ref_str)

        return {"answer": answer, "references": refs, "session_active": False}
    # ===== ูุชุงุจุนุฉ ุงููุฒุงุฑู =====
    if content.strip() in ["ููู", "ูุชุงุจุนุฉ", "ุงุณุชูุฑ"]:
        sess = sessions.get(user_id)

        if sess and sess.get("mode") == "ูุฒุงุฑู" and sess.get("pending_exams"):
            pending = sess["pending_exams"]
            batch = pending[:EXAMS_BATCH_SIZE]
            sess["pending_exams"] = pending[EXAMS_BATCH_SIZE:]

            text = ""
            for i, q in enumerate(batch, 1):
              text += f"{i}. {q['ุงููุต']} (ุณูุฉ {q['ุณูุฉ']})\n"

            if sess["pending_exams"]:
               text += f"\n๐ก ุงููุชุจูู: {len(sess['pending_exams'])} ุณุคุงู."
            else:
                text += "\nโ ุงูุชูุช ุฌููุน ุงูุฃุณุฆูุฉ."
                sessions.pop(user_id, None)

            return {
            "answer": text,
            "session_active": bool(sess.get("pending_exams"))
                 }
   
    # 4) ูุถุน "ูุฒุงุฑู"
    if mode == "ูุฒุงุฑู":
        year_token, rest = parse_exams_input(content)

        if not year_token or not rest:
            return {
                "answer": "ุงูุชุจ ุงูุตูุบุฉ ููุฐุง:\nูุซุงู: 2019,ุงูุฏุฑููุฉ"
            }

        years = [year_token] if year_token != "ุงููู" else ["ุงููู"]

        all_questions = collect_exam_questions_by_years(subject, years)
        if not all_questions:
            return {"answer": "ูุง ุชูุฌุฏ ุฃุณุฆูุฉ ููุฐู ุงูุณูุฉ."}

        # ุงููููุฉ ุฃู ุงูููุถูุน
        keyword = ",".join(rest).strip()

        matched = filter_and_rank_exams(all_questions, keyword)


        if not matched:
            return {"answer": f"ูู ุฃุฌุฏ ุฃุณุฆูุฉ ุชุญุชูู ุนูู '{keyword}'."}

        # ==== ุงูุนุฑุถ (10 + ููู) ====
        total = len(matched)
        first_batch = matched[:EXAMS_BATCH_SIZE]
        remaining = matched[EXAMS_BATCH_SIZE:]

        if remaining:
            sessions[user_id] = {
                "pending_exams": remaining,
                "mode": "ูุฒุงุฑู",
                "subject": subject  # โ ูุฐุง ูู ุงูุชุตุญูุญ ุงูุถุฑูุฑู
            }

        text = f"โ ูุฌุฏุช {total} ุณุคุงูุงู ูุญุชูู ุนูู '{keyword}':\n\n"
        for i, q in enumerate(first_batch, 1):
            text += f"{i}. {q.get('ุงููุต')} (ุณูุฉ {q.get('ุณูุฉ')})\n"

        if remaining:
            text += f"\n๐ก ุชุจูู {len(remaining)} ุณุคุงูุงู. ุงูุชุจ 'ููู' ูููุชุงุจุนุฉ."

        return {
            "answer": text,
            "session_active": bool(remaining)
        }
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
    
    
    
    
    
